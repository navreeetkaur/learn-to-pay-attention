{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = (X_train[:20000], Y_train[:20000]), (X_test[:2000], Y_test[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_dataset(x):\n",
    "    new_x = []\n",
    "    for i in range(len(x)):\n",
    "        new_x.append(zoom(x[i], (8.0,8.0,1.0)))\n",
    "        if (i%100)==0:\n",
    "            print(f'Done: {i}')\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0\n",
      "Done: 100\n",
      "Done: 200\n",
      "Done: 300\n",
      "Done: 400\n",
      "Done: 500\n",
      "Done: 600\n",
      "Done: 700\n",
      "Done: 800\n",
      "Done: 900\n",
      "Done: 1000\n",
      "Done: 1100\n",
      "Done: 1200\n",
      "Done: 1300\n",
      "Done: 1400\n",
      "Done: 1500\n",
      "Done: 1600\n",
      "Done: 1700\n",
      "Done: 1800\n",
      "Done: 1900\n",
      "Done: 2000\n",
      "Done: 2100\n",
      "Done: 2200\n",
      "Done: 2300\n",
      "Done: 2400\n",
      "Done: 2500\n",
      "Done: 2600\n",
      "Done: 2700\n",
      "Done: 2800\n",
      "Done: 2900\n",
      "Done: 3000\n",
      "Done: 3100\n",
      "Done: 3200\n",
      "Done: 3300\n",
      "Done: 3400\n",
      "Done: 3500\n",
      "Done: 3600\n",
      "Done: 3700\n",
      "Done: 3800\n",
      "Done: 3900\n",
      "Done: 4000\n",
      "Done: 4100\n",
      "Done: 4200\n",
      "Done: 4300\n",
      "Done: 4400\n",
      "Done: 4500\n",
      "Done: 4600\n",
      "Done: 4700\n",
      "Done: 4800\n",
      "Done: 4900\n",
      "Done: 5000\n",
      "Done: 5100\n",
      "Done: 5200\n",
      "Done: 5300\n",
      "Done: 5400\n",
      "Done: 5500\n",
      "Done: 5600\n",
      "Done: 5700\n",
      "Done: 5800\n",
      "Done: 5900\n",
      "Done: 6000\n",
      "Done: 6100\n",
      "Done: 6200\n",
      "Done: 6300\n",
      "Done: 6400\n",
      "Done: 6500\n",
      "Done: 6600\n",
      "Done: 6700\n",
      "Done: 6800\n",
      "Done: 6900\n",
      "Done: 7000\n",
      "Done: 7100\n",
      "Done: 7200\n",
      "Done: 7300\n",
      "Done: 7400\n",
      "Done: 7500\n",
      "Done: 7600\n",
      "Done: 7700\n",
      "Done: 7800\n",
      "Done: 7900\n",
      "Done: 8000\n",
      "Done: 8100\n",
      "Done: 8200\n",
      "Done: 8300\n",
      "Done: 8400\n",
      "Done: 8500\n",
      "Done: 8600\n",
      "Done: 8700\n",
      "Done: 8800\n",
      "Done: 8900\n",
      "Done: 9000\n",
      "Done: 9100\n",
      "Done: 9200\n",
      "Done: 9300\n",
      "Done: 9400\n",
      "Done: 9500\n",
      "Done: 9600\n",
      "Done: 9700\n",
      "Done: 9800\n",
      "Done: 9900\n",
      "Done: 10000\n",
      "Done: 10100\n",
      "Done: 10200\n",
      "Done: 10300\n",
      "Done: 10400\n",
      "Done: 10500\n",
      "Done: 10600\n",
      "Done: 10700\n",
      "Done: 10800\n",
      "Done: 10900\n",
      "Done: 11000\n",
      "Done: 11100\n",
      "Done: 11200\n",
      "Done: 11300\n",
      "Done: 11400\n",
      "Done: 11500\n",
      "Done: 11600\n",
      "Done: 11700\n",
      "Done: 11800\n",
      "Done: 11900\n",
      "Done: 12000\n",
      "Done: 12100\n",
      "Done: 12200\n",
      "Done: 12300\n",
      "Done: 12400\n",
      "Done: 12500\n",
      "Done: 12600\n",
      "Done: 12700\n",
      "Done: 12800\n",
      "Done: 12900\n",
      "Done: 13000\n",
      "Done: 13100\n",
      "Done: 13200\n",
      "Done: 13300\n",
      "Done: 13400\n",
      "Done: 13500\n",
      "Done: 13600\n",
      "Done: 13700\n",
      "Done: 13800\n",
      "Done: 13900\n",
      "Done: 14000\n",
      "Done: 14100\n",
      "Done: 14200\n",
      "Done: 14300\n",
      "Done: 14400\n",
      "Done: 14500\n",
      "Done: 14600\n",
      "Done: 14700\n",
      "Done: 14800\n",
      "Done: 14900\n",
      "Done: 15000\n",
      "Done: 15100\n",
      "Done: 15200\n",
      "Done: 15300\n",
      "Done: 15400\n",
      "Done: 15500\n",
      "Done: 15600\n",
      "Done: 15700\n",
      "Done: 15800\n",
      "Done: 15900\n",
      "Done: 16000\n",
      "Done: 16100\n",
      "Done: 16200\n",
      "Done: 16300\n",
      "Done: 16400\n",
      "Done: 16500\n",
      "Done: 16600\n",
      "Done: 16700\n",
      "Done: 16800\n",
      "Done: 16900\n",
      "Done: 17000\n",
      "Done: 17100\n",
      "Done: 17200\n",
      "Done: 17300\n",
      "Done: 17400\n",
      "Done: 17500\n",
      "Done: 17600\n",
      "Done: 17700\n",
      "Done: 17800\n",
      "Done: 17900\n",
      "Done: 18000\n",
      "Done: 18100\n",
      "Done: 18200\n",
      "Done: 18300\n",
      "Done: 18400\n",
      "Done: 18500\n",
      "Done: 18600\n",
      "Done: 18700\n",
      "Done: 18800\n",
      "Done: 18900\n",
      "Done: 19000\n",
      "Done: 19100\n",
      "Done: 19200\n",
      "Done: 19300\n",
      "Done: 19400\n",
      "Done: 19500\n",
      "Done: 19600\n",
      "Done: 19700\n",
      "Done: 19800\n",
      "Done: 19900\n"
     ]
    }
   ],
   "source": [
    "x_train = scale_dataset(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0\n",
      "Done: 100\n",
      "Done: 200\n",
      "Done: 300\n",
      "Done: 400\n",
      "Done: 500\n",
      "Done: 600\n",
      "Done: 700\n",
      "Done: 800\n",
      "Done: 900\n",
      "Done: 1000\n",
      "Done: 1100\n",
      "Done: 1200\n",
      "Done: 1300\n",
      "Done: 1400\n",
      "Done: 1500\n",
      "Done: 1600\n",
      "Done: 1700\n",
      "Done: 1800\n",
      "Done: 1900\n"
     ]
    }
   ],
   "source": [
    "x_test = scale_dataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = tf.convert_to_tensor(x_train, np.float32)\n",
    "x_test = tf.convert_to_tensor(x_test, np.float32)\n",
    "y_train = tf.convert_to_tensor(Y_train, np.float32)\n",
    "y_test = tf.convert_to_tensor(Y_test, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 6000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = x_train.numpy().shape[0]\n",
    "train_len = int(total*0.7)\n",
    "val_len = total-train_len\n",
    "train_len, val_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = [256,256,3]\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# training hyperparameters\n",
    "LEARNING_RATE = 1e-4\n",
    "MOMENTUM = 0.9\n",
    "RMSPROP_DECAY = 0.9     \n",
    "RMSPROP_EPSILON = 1.0              \n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "DISPLAY_STEP = 5 #10\n",
    "VALIDATION_STEP = 50 #1000\n",
    "SAVE_STEP = 10 #100\n",
    "CKPT_PATH = './ckpt_base'\n",
    "CKPT_PREFIX = os.path.join(CKPT_PATH, 'ckpt')\n",
    "SUMMARY_PATH = './summary_base'\n",
    "\n",
    "# net architecture hyperparamaters\n",
    "LAMBDA = 5e-4 #for weight decay\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# test hyper parameters\n",
    "K_PATCHES = 5\n",
    "TOP_K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train[:train_len], y_train[:train_len]))\n",
    "dataset = dataset.shuffle(100).batch(BATCH_SIZE)\n",
    "data_it = dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "testset = testset.shuffle(10).batch(1)\n",
    "test_it = testset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valset = tf.data.Dataset.from_tensor_slices((x_train[train_len:], y_train[train_len:]))\n",
    "valset = valset.shuffle(50).batch(BATCH_SIZE)\n",
    "val_it = valset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AlexNet(tfe.Network):\n",
    "\n",
    "    def __init__(self, training):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.training = training\n",
    "\n",
    "        # convolutional layers\n",
    "\n",
    "        conv_init = tf.contrib.layers.xavier_initializer_conv2d()\n",
    "\n",
    "        self.conv1 = self.track_layer(tf.layers.Conv2D(96, 11, 4, 'SAME', \n",
    "                                                        activation=tf.nn.relu, \n",
    "                                                        kernel_initializer=conv_init))\n",
    "        self.pool1 = self.track_layer(tf.layers.MaxPooling2D(3, 2, 'VALID'))\n",
    "\n",
    "        self.conv2 = self.track_layer(tf.layers.Conv2D(256, 5, 1, 'SAME', \n",
    "                                                        activation=tf.nn.relu,\n",
    "                                                        kernel_initializer=conv_init))\n",
    "        self.pool2 = self.track_layer(tf.layers.MaxPooling2D(3, 2, 'VALID'))\n",
    "\n",
    "        self.conv3 = self.track_layer(tf.layers.Conv2D(384, 3, 1, 'SAME', \n",
    "                                                        activation=tf.nn.relu,\n",
    "                                                        kernel_initializer=conv_init))\n",
    "\n",
    "        self.conv4 = self.track_layer(tf.layers.Conv2D(384, 3, 1, 'SAME', \n",
    "                                                        activation=tf.nn.relu,\n",
    "                                                        kernel_initializer=conv_init))\n",
    "\n",
    "        self.conv5 = self.track_layer(tf.layers.Conv2D(256, 3, 1, 'SAME', \n",
    "                                                        activation=tf.nn.relu,\n",
    "                                                        kernel_initializer=conv_init))\n",
    "        self.pool5 = self.track_layer(tf.layers.MaxPooling2D(3, 2, 'VALID'))\n",
    "\n",
    "        # fully connected layers\n",
    "\n",
    "        \n",
    "        fc_init = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "        self.fc1 = self.track_layer(tf.layers.Dense(4096, \n",
    "                                                        activation=tf.nn.relu,\n",
    "                                                        kernel_initializer=fc_init))\n",
    "        self.drop1 = self.track_layer(tf.layers.Dropout(DROPOUT))\n",
    "        \n",
    "        self.fc2 = self.track_layer(tf.layers.Dense(4096, \n",
    "                                                        activation=tf.nn.relu,\n",
    "                                                        kernel_initializer=fc_init))\n",
    "        self.drop2 = self.track_layer(tf.layers.Dropout(DROPOUT))\n",
    "\n",
    "        \n",
    "        \n",
    "        self.out = self.track_layer(tf.layers.Dense(NUM_CLASSES,\n",
    "                                                        kernel_initializer=fc_init))\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\" Function that executes the model \"\"\"\n",
    "        output = self.conv1(x)\n",
    "#         print(f'Conv1: {output.numpy().shape}')\n",
    "        output = tf.nn.lrn(output, depth_radius=2, bias=1.0, alpha=2e-05, beta=0.75)\n",
    "        output = self.pool1(output)\n",
    "#         print(f'Pool1: {output.numpy().shape}')\n",
    "\n",
    "        output = self.conv2(output)\n",
    "#         print(f'Conv2: {output.numpy().shape}')\n",
    "        output = tf.nn.lrn(output, depth_radius=2, bias=1.0, alpha=2e-05, beta=0.75)\n",
    "        output = self.pool2(output)\n",
    "#         print(f'Pool2: {output.numpy().shape}')\n",
    "\n",
    "        output = self.conv3(output)\n",
    "#         print(f'Conv3: {output.numpy().shape}')\n",
    "\n",
    "        output = self.conv4(output)\n",
    "#         print(f'Conv4: {output.numpy().shape}')\n",
    "        output_conv4 = output \n",
    "\n",
    "        output = self.conv5(output)\n",
    "#         print(f'Conv5: {output.numpy().shape}')\n",
    "        output_conv5 = output \n",
    "        output = self.pool5(output)\n",
    "#         print(f'Pool5: {output.numpy().shape}')\n",
    "\n",
    "        output = tf.layers.flatten(output)\n",
    "#         print(f'Flatten1: {output.numpy().shape}')\n",
    "\n",
    "        output = self.fc1(output)\n",
    "#         print(f'FC1: {output.numpy().shape}')\n",
    "        if self.training:\n",
    "            output = self.drop1(output)\n",
    "            \n",
    "        output = self.fc2(output)\n",
    "#         print(f'FC2: {output.numpy().shape}')\n",
    "        if self.training:\n",
    "            output = self.drop2(output)\n",
    "            \n",
    "        output = self.out(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-52d5a24bb02b>:4: Network.__init__ (from tensorflow.contrib.eager.python.network) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please inherit from `tf.keras.Model`, and see its documentation for details. `tf.keras.Model` should be a drop-in replacement for `tfe.Network` in most cases, but note that `track_layer` is no longer necessary or supported. Instead, `Layer` instances are tracked on attribute assignment (see the section of `tf.keras.Model`'s documentation on subclassing). Since the output of `track_layer` is often assigned to an attribute anyway, most code can be ported by simply removing the `track_layer` calls.\n",
      "\n",
      "`tf.keras.Model` works with all TensorFlow `Layer` instances, including those from `tf.layers`, but switching to the `tf.keras.layers` versions along with the migration to `tf.keras.Model` is recommended, since it will preserve variable names. Feel free to import it with an alias to avoid excess typing :).\n",
      "WARNING:tensorflow:** tfe.Network is deprecated and will be removed in a future version.\n",
      "\n",
      "Please inherit from `tf.keras.Model`, and see its documentation for details. `tf.keras.Model` should be a drop-in replacement for `tfe.Network` in most cases, but note that `track_layer` is no longer necessary or supported. Instead, `Layer` instances are tracked on attribute assignment (see the section of `tf.keras.Model`'s documentation on subclassing). Since the output of `track_layer` is often assigned to an attribute anyway, most code can be ported by simply removing the `track_layer` calls.\n",
      "\n",
      "`tf.keras.Model` works with all TensorFlow `Layer` instances, including those from `tf.layers`, but switching to the `tf.keras.layers` versions along with the migration to `tf.keras.Model` is recommended, since it will preserve variable names. Feel free to import it with an alias to avoid excess typing :).\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation Warning: create_summary_file_writer was renamed to create_file_writer\n"
     ]
    }
   ],
   "source": [
    "writer = tf.contrib.summary.create_summary_file_writer(SUMMARY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=LEARNING_RATE, momentum=MOMENTUM)\n",
    "# optimizer = tf.train.RMSPropOptimizer(learning_rate=LEARNING_RATE, RMSPROP_DECAY,momentum=MOMENTUM,epsilon=RMSPROP_EPSILON)\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "# opt = tf.train.GradientDescent(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = tfe.Checkpoint(optimizer=optimizer, model=model, optimizer_step=tf.train.get_or_create_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(model, mode, x, y):\n",
    "    logits = model(x)\n",
    "    y = list(y.numpy().reshape(y.numpy().shape[0],))\n",
    "    y = tf.one_hot(y, NUM_CLASSES)\n",
    "    loss_value = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=logits)\n",
    "#     loss_value = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = y), name=\"cross_entropy_loss\")\n",
    "    weight_decay = tf.reduce_sum(LAMBDA * tf.stack([tf.nn.l2_loss(v) for v in model.variables]))\n",
    "\n",
    "    total_loss = loss_value + weight_decay\n",
    "\n",
    "    tf.contrib.summary.scalar(mode, '/loss', total_loss)\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(model, mode, x, y):\n",
    "#     pred = tf.nn.softmax(model(x))\n",
    "#     y = tf.one_hot(y, NUM_CLASSES)\n",
    "#     accuracy_value = tf.reduce_sum(\n",
    "#                 tf.cast(\n",
    "#                     tf.equal(\n",
    "#                         tf.argmax(pred, axis=1, output_type=tf.int64),\n",
    "#                         tf.argmax(y, axis=1, output_type=tf.int64)\n",
    "#                     ),\n",
    "#                     dtype=tf.float32\n",
    "#                 ) \n",
    "#             ) / float(pred.shape[0].value)\n",
    "\n",
    "    pred = tf.cast(tf.argmax(tf.nn.softmax(model(x)),axis=1), dtype=tf.float32)\n",
    "    equality = tf.equal(pred, y)\n",
    "    accuracy_value = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "    \n",
    "    tf.contrib.summary.scalar(mode, '/accuracy', accuracy_value)\n",
    "\n",
    "    return accuracy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_time(time):\n",
    "    \"\"\" It formats a datetime to print it\n",
    "        Args:\n",
    "            time: datetime\n",
    "        Returns:\n",
    "            a formatted string representing time\n",
    "    \"\"\"\n",
    "    m, s = divmod(time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    d, h = divmod(h, 24)\n",
    "    return ('{:02d}d {:02d}h {:02d}m {:02d}s').format(int(d), int(h), int(m), int(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.train.get_global_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables = (model.variables + optimizer.variables() + [global_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1\n",
      "step: 2\n",
      "step: 3\n",
      "step: 4\n",
      "step: 5\n",
      "Epoch: 000 Step/Batch: 005 Step mean time: 25230ms \n",
      "Loss: 11.6123896 Training accuracy: 0.1064\n",
      "step: 6\n",
      "step: 7\n",
      "step: 8\n",
      "step: 9\n",
      "step: 10\n",
      "Epoch: 000 Step/Batch: 010 Step mean time: 25581ms \n",
      "Loss: 5.7429338 Training accuracy: 0.0978\n",
      "Variables saved\n",
      "step: 11\n",
      "step: 12\n",
      "step: 13\n",
      "step: 14\n",
      "step: 15\n",
      "Epoch: 000 Step/Batch: 015 Step mean time: 27602ms \n",
      "Loss: 5.1828890 Training accuracy: 0.0961\n",
      "step: 16\n",
      "step: 17\n",
      "step: 18\n",
      "step: 19\n",
      "step: 20\n",
      "Epoch: 000 Step/Batch: 020 Step mean time: 26802ms \n",
      "Loss: 5.1045966 Training accuracy: 0.1005\n",
      "Variables saved\n",
      "step: 21\n",
      "step: 22\n",
      "step: 23\n",
      "step: 24\n",
      "step: 25\n",
      "Epoch: 000 Step/Batch: 025 Step mean time: 26074ms \n",
      "Loss: 5.0344782 Training accuracy: 0.1218\n",
      "step: 26\n",
      "step: 27\n",
      "step: 28\n",
      "step: 29\n",
      "step: 30\n",
      "Epoch: 000 Step/Batch: 030 Step mean time: 25606ms \n",
      "Loss: 5.0422287 Training accuracy: 0.0978\n",
      "Variables saved\n",
      "step: 31\n",
      "step: 32\n",
      "step: 33\n",
      "step: 34\n",
      "step: 35\n",
      "Epoch: 000 Step/Batch: 035 Step mean time: 25116ms \n",
      "Loss: 5.0483422 Training accuracy: 0.0936\n",
      "step: 36\n",
      "step: 37\n",
      "step: 38\n",
      "step: 39\n",
      "step: 40\n",
      "Epoch: 000 Step/Batch: 040 Step mean time: 24715ms \n",
      "Loss: 5.0000196 Training accuracy: 0.1162\n",
      "Variables saved\n",
      "step: 41\n",
      "step: 42\n",
      "step: 43\n",
      "step: 44\n",
      "step: 45\n",
      "Epoch: 000 Step/Batch: 045 Step mean time: 24633ms \n",
      "Loss: 4.9135199 Training accuracy: 0.1104\n",
      "step: 46\n",
      "step: 47\n",
      "step: 48\n",
      "step: 49\n",
      "step: 50\n",
      "Epoch: 000 Step/Batch: 050 Step mean time: 24361ms \n",
      "Loss: 4.8372917 Training accuracy: 0.1012\n",
      "Elapsed time: 00d 00h 23m 41s --- Loss: 4.9001737 Validation accuracy: 0.1002\n",
      "Variables saved\n",
      "step: 51\n",
      "step: 52\n",
      "step: 53\n",
      "step: 54\n",
      "step: 55\n",
      "Epoch: 000 Step/Batch: 055 Step mean time: 24245ms \n",
      "Loss: 4.8639297 Training accuracy: 0.0976\n",
      "step: 56\n",
      "step: 57\n",
      "step: 58\n",
      "step: 59\n",
      "step: 60\n",
      "Epoch: 000 Step/Batch: 060 Step mean time: 24123ms \n",
      "Loss: 4.8127728 Training accuracy: 0.1063\n",
      "Variables saved\n",
      "step: 61\n",
      "step: 62\n",
      "step: 63\n",
      "step: 64\n",
      "step: 65\n",
      "Epoch: 000 Step/Batch: 065 Step mean time: 24073ms \n",
      "Loss: 4.8489618 Training accuracy: 0.0887\n",
      "step: 66\n",
      "step: 67\n",
      "step: 68\n",
      "step: 69\n",
      "step: 70\n",
      "Epoch: 000 Step/Batch: 070 Step mean time: 24007ms \n",
      "Loss: 4.9358058 Training accuracy: 0.1082\n",
      "Variables saved\n",
      "step: 71\n",
      "step: 72\n",
      "step: 73\n",
      "step: 74\n",
      "step: 75\n",
      "Epoch: 000 Step/Batch: 075 Step mean time: 23902ms \n",
      "Loss: 4.7772255 Training accuracy: 0.0939\n",
      "step: 76\n",
      "step: 77\n",
      "step: 78\n",
      "step: 79\n",
      "step: 80\n",
      "Epoch: 000 Step/Batch: 080 Step mean time: 23784ms \n",
      "Loss: 4.7546210 Training accuracy: 0.1110\n",
      "Variables saved\n",
      "step: 81\n",
      "step: 82\n",
      "step: 83\n",
      "step: 84\n",
      "step: 85\n",
      "Epoch: 000 Step/Batch: 085 Step mean time: 23627ms \n",
      "Loss: 4.7129173 Training accuracy: 0.1113\n",
      "step: 86\n",
      "step: 87\n",
      "step: 88\n",
      "step: 89\n",
      "step: 90\n",
      "Epoch: 000 Step/Batch: 090 Step mean time: 23484ms \n",
      "Loss: 4.6683865 Training accuracy: 0.1160\n",
      "Variables saved\n",
      "step: 91\n",
      "step: 92\n",
      "step: 93\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "step_time = 0.0\n",
    "global_step = 0\n",
    "# with writer.as_default():\n",
    "#     with tf.contrib.summary.record_summaries_every_n_global_steps(DISPLAY_STEP):\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for (batch_i,datum) in enumerate(data_it):\n",
    "        global_step = tf.train.get_global_step()\n",
    "#                 global_step = tf.train.get_or_create_global_step()\n",
    "        step = global_step.numpy() + 1\n",
    "#         global_step += 1\n",
    "        print(f'step: {step}')\n",
    "        step_start_time = int(round(time.time() * 1000))\n",
    "        optimizer.minimize(lambda: loss(model, 'train', datum[0], datum[1]), global_step=global_step)\n",
    "\n",
    "        step_end_time = int(round(time.time() * 1000))\n",
    "        step_time = step_time + step_end_time - step_start_time\n",
    "\n",
    "        if (step % DISPLAY_STEP) == 0:\n",
    "            l = loss(model, 'train', datum[0], datum[1])\n",
    "            a = accuracy(model, 'train', datum[0], datum[1]).numpy()\n",
    "            print ('Epoch: {:03d} Step/Batch: {:03d} Step mean time: {:04d}ms \\nLoss: {:.7f} Training accuracy: {:.4f}'.format(epoch, step, int(step_time / step), l, a))\n",
    "\n",
    "        if (step % VALIDATION_STEP) == 0:\n",
    "            val_images, val_labels = val_it.get_next()\n",
    "            l = loss(model, 'val', val_images, val_labels)\n",
    "            a = accuracy(model, 'val', val_images, val_labels).numpy()\n",
    "            int_time = time.time() - start_time\n",
    "            print ('Elapsed time: {} --- Loss: {:.7f} Validation accuracy: {:.4f}'.format(format_time(int_time), l, a))\n",
    "\n",
    "        if (step % SAVE_STEP) == 0:\n",
    "            tfe.Saver(all_variables).save(os.path.join(CKPT_PATH, 'net.ckpt'), global_step=global_step)\n",
    "            print('Variables saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt_base/net.ckpt-50\n"
     ]
    }
   ],
   "source": [
    "tfe.Saver(model.variables).restore(tf.train.latest_checkpoint(CKPT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ins = test_it.get_next()\n",
    "x = ins[0]\n",
    "y = ins[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_accuracy(x, y):\n",
    "    pred = tf.cast(tf.argmax(tf.nn.softmax(model(x)),axis=1), dtype=tf.float32)\n",
    "    equality = tf.equal(pred, y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples done:     1/1000 ---- Acc: 0.0000 \n",
      "Examples done:   101/1000 ---- Acc: 0.3465 \n",
      "Examples done:   201/1000 ---- Acc: 0.3134 \n",
      "Examples done:   301/1000 ---- Acc: 0.2990 \n",
      "Examples done:   401/1000 ---- Acc: 0.3092 \n",
      "Examples done:   501/1000 ---- Acc: 0.3054 \n",
      "Examples done:   601/1000 ---- Acc: 0.3278 \n",
      "Examples done:   701/1000 ---- Acc: 0.3224 \n",
      "Examples done:   801/1000 ---- Acc: 0.3159 \n",
      "Examples done:   901/1000 ---- Acc: 0.3274 \n",
      "---- Final accuracy ----\n",
      "Acc: 0.3260 \n",
      "Error rate: 0.6740 \n"
     ]
    }
   ],
   "source": [
    "test_examples = x_test.numpy().shape[0]\n",
    "\n",
    "total_acc = 0.\n",
    "\n",
    "for (ex_i, datum) in enumerate(test_it):\n",
    "#     print(ex_i)\n",
    "    images = datum[0]\n",
    "    label = datum[1]\n",
    "\n",
    "    acc = test_accuracy(images, label)\n",
    "    total_acc += acc\n",
    "\n",
    "    if (ex_i % 100) == 0:\n",
    "        print ('Examples done: {:5d}/{} ---- Acc: {:.4f} '.format(ex_i + 1, test_examples, total_acc / (ex_i + 1)))\n",
    "\n",
    "print ('---- Final accuracy ----')\n",
    "print ('Acc: {:.4f} '.format(total_acc / test_examples))\n",
    "print ('Error rate: {:.4f} '.format(1 - (total_acc / test_examples) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ell-881-2018-deep-learning",
   "language": "python",
   "name": "ell-881-2018-deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
